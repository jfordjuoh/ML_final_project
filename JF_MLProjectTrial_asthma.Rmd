---
title: "ML Project Trial"
author: Judy Fordjuoh
date: April 14, 2022
output: word_document
---
We aimed to evaluate the association between a broad range of prenatal and postnatal lifestyle and environmental exposures and lung function in children.

#The data is unbalance for the outcome asthma (0:1159 1:142) Are we able to sample up/down in ensemble methods? Specifically the bagging and the rf I'm doing. 


```{r libraries, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)  

#Exposome contains all of the environmental features measured on children. Phenotype contains health outcomes measured during the study. Covariate contains demographics and maternal information during pregnancy. Codebook is a detailed listing of all variables within the data frames. 
library(tidyverse)
library(caret)
library(dplyr)
library(rpart)
library(rpart.plot)
library(pROC)
library(e1071)
library(knitr)
library(randomForest)

#Load data using path of where file is stored
load("/Users/judyfordjuoh/Desktop/Machine Learning/exposome.RData")
```

Question: Can the quality of the built environment during a mothers pregnancy predict whether an individuals develops asthma within their life? Restructured question: Does specific factors of the built environment during a mothers pregnancy predict whether an individuals develops asthma within their life?

```{r data_prep, include=FALSE}
#exposome data
ex1 = exposome %>%
    select(ID, h_pamod_t3_None, h_greenyn300_preg_None, h_pm10_ratio_preg_None, h_accesslines300_preg_dic0, h_accesspoints300_preg_Log, 	
h_builtdens300_preg_Sqrt, h_connind300_preg_Sqrt, h_walkability_mean_preg_None) 

#Check distributions, missing data etc for exposome.
summary(ex1)
ex1 <- na.omit(ex1)

#phenotype data
p1 = phenotype %>%
  mutate(asthma = as.factor(hs_asthma)) %>%
  select(ID, asthma) 

#Check distributions, missing data etc for phenotype.
summary(p1) #data is not balanced for the outcome asthma. 0:1159 1:142
p1 <- na.omit(p1)

#Merge all data frames into a single data frame. FYI, this is just a shortcut by combining baseR with piping from tidyverse. There are other ways of merging across three data frames that are likely more elegant.
studydata <- merge(ex1,p1,by = "ID")  

#Strip off ID Variable
studydata$ID <- NULL

#Partition data for use in demonstration
set.seed(100)
train.indices <- createDataPartition(y = studydata$asthma,p = 0.7,list = FALSE)
train_asthma <- studydata[train.indices, ]
test_asthma <- studydata[-train.indices, ]

```


#BAGGING
```{r BAG}
set.seed(100) 

#Example code using other bagging methods. This is a treebagg method, which gives you greater control of the hyperparameters
controlsettings<-trainControl(method="cv", number=1)
bagging_asthma<-train(asthma ~., data=train_asthma, method="treebag", trcontrol=controlsettings, nbagg=10, control=rpart.control(minsplit=20, cp=0))

bagging_asthma$results
varImp(bagging_asthma)
plot(varImp(bagging_asthma))
confusionMatrix(bagging_asthma) #0.8809
```


# RANDOM FOREST
```{r RANDOM FOREST}
set.seed(100)

#Trying three different values of mtry (square root, half)
# since we are not specifying our cross validation, the default is a bootstrap. R is bootstrapping 25 times.

mtry.vals <- c(ncol(train_asthma) - 1, sqrt(ncol(train_asthma) - 1), 0.5*ncol(train_asthma) - 1)

mtry.grid <- expand.grid(.mtry = mtry.vals)
rf_asthma <- train(asthma ~., data = train_asthma, method = "rf", metric = "Accuracy", tuneGrid = mtry.grid, ntree = 100)

confusionMatrix(rf_asthma) #Accuracy (average) : 0.8868
rf_asthma$results
rf_asthma$bestTune
rf_asthma$finalModel

varImp(rf_asthma)
plot(varImp(rf_asthma))

varImpPlot(rf_asthma$finalModel)
#Most important variables: h_builtdens300_preg_Sqrt = 100.000, h_pm10_ratio_preg_None = 88.815, h_connind300_preg_Sqrt = 77.481
#Least important variables: h_pamod_t3 = 2.194, h_accesslines300_preg_dic0 = 0.000
```


# LASSO
```{r LASSO}
#LASSO
#NTS: first create a grid to search lambda
lambda <- 10^seq(-5,5, length = 100)

set.seed(100)

lasso_m <- train(
  asthma ~., data = train_asthma, method = "glmnet", trControl = trainControl("cv", number = 10, sampling = "down"), preProc = c("center", "scale"), tuneGrid = expand.grid(alpha = 1, lambda = lambda)
)

#Print the values of alpha and lambda that gave best prediction
lasso_m$bestTune %>% knitr::kable() # 1(alpha)|0.004(lambda)| (Accuracy)

#Print all of the options examined
lasso_m$results %>% knitr::kable()

# Model coefficients
coef(lasso_m$finalModel, lasso_m$bestTune$lambda) 
#h_pamod_t3_NoneOften and h_pm10_ratio_preg_None went to 0. The largest beta is h_accesspoints300_preg_Log = 4.794318e-01

#Confusion Matrix
confusionMatrix(lasso_m) #Accuracy (average) : 0.5417
```


#Support Vector Machine
```{r data_restructing_SVM}
#we are doing an SVM because SVM offers very high accuracy compared to other classifiers such as logistic regression, and decision trees. It is known for its kernel trick to handle nonlinear input spaces.

#add levels to the asthma variable because I'll need it for SVM.
studydata_svm = studydata 

summary(studydata_svm) #data is unbalanced. No asthma is 1159 and asthma is 142

levels(studydata_svm$asthma) <- c("no_asthma", "yes_asthma")

#Set No Asthma as Reference Level
studydata_svm$asthma <- relevel(studydata_svm$asthma, ref = "no_asthma")

set.seed(100)
trainsvm.indices <- createDataPartition(y = studydata_svm$asthma,p = 0.7,list = FALSE)
trainsvm_asthma <- studydata_svm[trainsvm.indices, ]
testsvm_asthma <- studydata_svm[-trainsvm.indices, ]
```
 
```{r SVM_actual_code}

set.seed(100)

#Set 10-fold cross-validation. Note if you want predicted probabilities, you need to set class Probs=True
traincontrol_svm <- trainControl(method = "cv", number = 10, sampling = "up", classProbs = T)


#Train model. Note we are scaling data
svm_asthma <- train(asthma ~ ., data = trainsvm_asthma, method = "svmLinear", trControl = traincontrol_svm, preProcess = c("center", "scale"))

svm_asthma #Accuracy:0.5603

#Incorporate different values for cost (C)
svm_asthma2 <- train(asthma ~ ., data = trainsvm_asthma, method = "svmLinear",  trControl = traincontrol_svm, preProcess = c("center", "scale"), tuneGrid = expand.grid(C = seq(0.001,2, length = 30)))

#Visualize accuracy versus values of C
plot(svm_asthma2)

#Obtain metrics of accuracy from training
confusionMatrix(svm_asthma2) #Accuracy: 0.5833

#See information about final model
svm_asthma2$finalModel

#Make predictions in testset
svm_asthma2_predtest <- predict(svm_asthma2, testsvm_asthma)

#Get evaluation metrics from test set
confusionMatrix(svm_asthma2_predtest, testsvm_asthma$asthma, positive = "yes_asthma")
#Accuracy:0.5296 with a 95% CI of (0.4786, 0.5801) with a sensitivity of 0.64286 and a specificity of 0.5158

#Create ROC Curve for Analysis
pred.prob <- predict(svm_asthma2, testsvm_asthma, type = "prob")

#Another potential evaluation: Area under the Reciver Operating Curve (AUROC)
analysis <- roc(response = testsvm_asthma$asthma, predictor = pred.prob[,2])
plot(1 - analysis$specificities,analysis$sensitivities,type = "l",
ylab = "Sensitivity",xlab = "1-Specificity",col = "black",lwd = 2,
main = "ROC Curve for Asthma Classification")
abline(a = 0,b = 1)

#Variable Importance
varImp(svm_asthma2)
#h_builtdens300_preg_Sqrt : 100.000, h_pm10_ratio_preg_None: 92.350, h_accesspoints300_preg_Log = 88.992
```

